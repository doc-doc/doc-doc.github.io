<!DOCTYPE html>
<html lang="en"> 
<head>
	<title>CV - Junbin Xiao / Home Page</title>
	
	<!-- Meta -->
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta name="description" content="">
	<meta name="author" content="Xiaoying Riley at 3rd Wave Media">    
	<link rel="shortcut icon" href="xiaojb.ico"> 
	
	<!-- Google Fonts -->
	<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700,900" rel="stylesheet">
	
	<!-- FontAwesome JS-->
	<script defer src="assets/fontawesome/js/all.min.js"></script>
	
	<!-- Theme CSS -->  
	<link id="theme-style" rel="stylesheet" href="assets/css/devresume.css">

</head> 

<body>
	<div class="main-wrapper">
		<div class="container px-3 px-lg-5">
			<article class="resume-wrapper mx-auto theme-bg-light p-5 mb-5 my-5 shadow-lg">
				
				<div class="resume-header">
					<div class="row align-items-center">
						<div class="resume-title col-12 col-md-6 col-lg-8 col-xl-9">
							<h2 class="resume-name mb-0 text-uppercase">Junbin Xiao (<font face="STXingkai">肖俊斌</font>)</h2>
							<div class="resume-tagline mb-3 mb-md-0">Ph.D in Computer Science</div>
						</div><!--//resume-title-->
						<div class="col-12 col-md-3 col-xl-2 text-center">
						    <img class="resume-profile-image mb-3 mb-md-0 me-md-5  ms-md-0 rounded mx-auto" src="assets/images/profile.jpg" alt="image">
						</div>
						
						<div class="resume-contact col-12 col-md-6 col-lg-4 col-xl-3">
							 <ul class="list-unstyled mb-0">
							 <a href="https://scholar.google.com.hk/citations?hl=zh-CN&user=3pxbyHYAAAAJ"><i class="fab fa-google"></i>oogle Scholar</a> / <a href="https://dblp.org/pid/242/4518.html">DBLP</a>
							  / <a href="https://github.com/doc-doc"><i class="fab fa-google"></i>ithub</a> / <a href="#">CV</a>
							  <li class="mb-0"><i class="fas fa-map-marker-alt fa-fw fa-lg me-2"></i>AS6-05-25, SoC, NUS</li>
							</ul> 
						</div><!--//resume-contact-->
						
					</div><!--//row-->
					
				</div><!--//resume-header-->
				<hr>
				<div class="resume-intro py-3">
					<div class="row align-items-center">					
						<div class="col text-start">
								I am a Research Fellow at NUS, working with Prof Angela Yao. Previously, I obtained my PhD at the <a href="https://www.comp.nus.edu.sg/cs/" target="_blank">Department of Computer Science, National University of Singapore (NUS)</a>,
								supervised by <a href="https://www.chuatatseng.com/" target="_blank">Prof. Tat-Seng Chua</a>  and closely collaborated with <a href="https://www.comp.nus.edu.sg/~ayao/"> Prof. Angela Yao </a>.  
								From Nov. 2021 to Apr. 2022, I worked as a research intern at <a href="https://sail.sea.com/" target="_blank">Sea AI Lab (SAIL)</a> and was jointly advised by <a href="https://panzhous.github.io/", target="_blank">Dr. Pan Zhou</a> and <a href="https://yanshuicheng.ai/", target="_blank">Prof. Shuicheng Yan</a>. 
								Prior to that, I received my M.S.Eng degree from the <a href="http://www.ict.ac.cn/", target="_blank">Institute of Computing Technology, Chinese Academy of Sciences</a> at 2018 and B.Eng. degree from <a href="https://www.scu.edu.cn/" target="_blank">Sichuan University</a> at 2015, respectively.					
								<p>
								My research focuses on fine-grained video-language understanding, covering the topics of VideoQA and Video Grounding. The techniques emphasize video structural representation learning and its interaction with languages, as well as Robustness and Interpretability. <font color="#FF4500"> I am looking forward to working with Research Interns/Assistants/Visiting Students. (If you are interested in my research, please contact to junbin at comp dot nus dot edu dot sg. Students with CV/NLP/MultiModal background are preferred.)
								</font>
							</div><!--//col-->
					</div>
				
				</div><!--//resume-intro-->
				<hr>
				<div class="resume-body">
					<div class="row">
						<div class="resume-main col-12 col-lg-8 col-xl-9   pe-0   pe-lg-5">
							<section class="work-section py-3">
								<h3 class="text-uppercase resume-section-heading mb-4">News</h3>
								<div class="item mb-3">				
									
									<div class="item-heading row align-items-center mb-2">
										<p class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">Invited to be reviewer in NeurIPS'23 dataset and benchmark track.</p>
										<div class="item-meta col-12 col-md-6 col-lg-4 text-muted text-start text-md-end">NeurIPS | Jun. 2023</div>
									</div>
									<div class="item-heading row align-items-center mb-2">
										<p class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">Invited to be reviewer in ACM MM'23.</p>
										<div class="item-meta col-12 col-md-6 col-lg-4 text-muted text-start text-md-end">ACM MM | Apr. 2023</div>
									</div>

									<div class="item-heading row align-items-center mb-2">
										<p class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0"><a href="assets/images/news/oral-defense.jpg">Successfully defensed my Ph.D.</a></p>
										<div class="item-meta col-12 col-md-6 col-lg-4 text-muted text-start text-md-end">NUS | Mar. 2023</div>
										<div class="item-content">
											<p>
											<b>Thesis</b>: <a href="https://scholarbank.nus.edu.sg/handle/10635/239063">Visual Relation Driven Video Question Answering.</a>
												<b>Supervisor</b>: Tat-Seng Chua.
												<b>Committee</b>: Prof. <a href="https://www.comp.nus.edu.sg/cs/people/mohan/">Mohan Kankanhalli</a>, Prof. <a href="https://www.comp.nus.edu.sg/cs/people/rogerz/">Roger Zimmermann</a>.
												<b>Chair</b>: Prof. <a href="https://www.comp.nus.edu.sg/cs/people/tsim/">Terence Sim</a>
											</p>
										</div>
									</div>

									<div class="item-heading row align-items-center mb-2">
										<p class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">Invited to be reviewer in ICCV'23.</p>
										<div class="item-meta col-12 col-md-6 col-lg-4 text-muted text-start text-md-end">ICCV | Feb. 2023</div>
									</div>
									<div class="item-heading row align-items-center mb-2">
										<p class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">Invited to be reviewer in CVPR'23.</p>
										<div class="item-meta col-12 col-md-6 col-lg-4 text-muted text-start text-md-end">CVPR | Oct. 2022</div>
									</div>
									<div class="item-heading row align-items-center mb-2">
										<p class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">Receive the <font color="#FF4500">Dean's Graduate Research Excellence Award</font>.</p>
										<div class="item-meta col-12 col-md-6 col-lg-4 text-muted text-start text-md-end">NUS | Aug. 2022</div>
									</div>
									<div class="item-heading row align-items-center mb-2">
										<p class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">Invited to serve as PC member in AAAI'23.</p>
										<div class="item-meta col-12 col-md-6 col-lg-4 text-muted text-start text-md-end">AAAI | Aug. 2022</div>
									</div>
									
									<div class="item-heading row align-items-center mb-2">
										<p class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">One VideoQA paper is chosen as <font color="#FF4500">Best Paper FinalList</font> in CVPR'22</font>.</p>
										<div class="item-meta col-12 col-md-6 col-lg-4 text-muted text-start text-md-end">CVPR | Jun. 2022</div>
									</div>
									
									
								</div><!--//item-->
								
								
							</section><!--//work-section-->

							
							<section class="project-section py-3">
								<h3 class="text-uppercase resume-section-heading mb-4">Featured Publications</h3>
									<div class="item mb-3">
									<div class="item row">
										<a class="col-md-3 col-5" href="https://arxiv.org/abs/2302.13668" target="_blank">
											<img class="img-fluid project-image rounded shadow-sm" src="assets/images/research/arxiv/CoVGT.png" alt="CoVGT" height="160" width="160"/>
										</a>
										<div class="desc col-md-9 col-12">
											<h6><a href="https://arxiv.org/abs/2302.13668" target="_blank">Contrastive Video Question Answering via Video Graph Transformer</a></h6>
											<p class="item-meta col-12 col-md-12 col-lg-12 "> <b>Junbin Xiao</b>, Pan Zhou, Angela Yao, Yicong Li, Richang Hong, Shuicheng Yan, Tat-Seng Chua</p>
											<div class="item-meta col-12 col-md-12 col-lg-14">
												[<a href="https://ieeexplore.ieee.org/document/10172254">T-PAMI'23</a>
												/ Project Page
												/ <a href="https://github.com/doc-doc/CoVGT">Github</a>
												/ <a href="https://scholar.google.com/scholar_lookup?arxiv_id=2302.13668">Cite</a>]
													
											</div>                        
										</div><!--//desc-->                          
									</div><!--//item-->
									</div><!--//resume-main-->
									<div class="item mb-3">
									<div class="item row">
										<a class="col-md-3 col-5" href="https://aclanthology.org/2022.emnlp-main.432.pdf" target="_blank">
											<img class="img-fluid project-image rounded shadow-sm" src="assets/images/research/emnlp/dataset.png" alt="VideoQA Survey" height="160" width="160"/>
										</a>
										<div class="desc col-md-8 col-12">
											<h6><a href="https://aclanthology.org/2022.emnlp-main.432.pdf" target="_blank">Video Question Answering: Datasets, Algorithms and Challenges</a></h6>
											<p class="item-meta col-12 col-md-12 col-lg-14 "> Yaoyao Zhong<sup>*</sup>, <b>Junbin Xiao</b><sup>*</sup>， Wei Ji<sup>*</sup>, Yicong Li, Weihong Deng, Tat-Seng Chua</p>
											<div class="item-meta col-12 col-md-12 col-lg-14">
												[<a href="https://aclanthology.org/2022.emnlp-main.432/">EMNLP'22</a>
												/ Project Page
												/ <a href="https://github.com/VRU-NExT/VideoQA" target="_blank">Github</a>
												/ <a href="https://aclanthology.org/2022.emnlp-main.432/" target="_blank">Cite</a>]
											</div>                        
										</div><!--//desc-->                          
									</div><!--//item-->
									</div><!--//resume-main-->
									<div class="item mb-3">
									<div class="item row">
										<a class="col-md-3 col-5" href="https://arxiv.org/abs/2207.05342" target="_blank">
											<img class="img-fluid project-image rounded shadow-sm" src="assets/images/research/eccv/VGT.png" alt="VGT" height="160" width="160"/>
										</a>
										<div class="desc col-md-8 col-12">
											<h6><a href="https://arxiv.org/abs/2207.05342" target="_blank">Video Graph Transformer for Video Question Answering</a></h6>
											<p class="item-meta col-12 col-md-12 col-lg-14 "> <b>Junbin Xiao</b>, Pan Zhou, Tat Seng Chua, Shuicheng Yan</p>
											<div class="item-meta col-12 col-md-12 col-lg-14">
												[ <a href="https://link.springer.com/chapter/10.1007/978-3-031-20059-5_3">ECCV'22</a>
												/ Project Page
												/ <a href="https://github.com/sail-sg/VGT" target="_blank">Github</a>
												/ <a href="https://doc-doc.github.io/docs/VGT-ECCV22-poster.pdf" target="_blank">Poster</a>
												/ <a href="https://scholar.google.com.sg/scholar?q=Video+Graph+Transformer+for+Video+Question+Answering&hl=zh-CN&as_sdt=0&as_vis=1&oi=scholart" target="_blank">Cite</a>]
											</div>                        
										</div><!--//desc-->                          
									</div><!--//item-->
									</div><!--//resume-main-->
									<div class="item mb-3">
									<div class="item row">
										<a class="col-md-3 col-5" href="https://arxiv.org/pdf/2207.12783.pdf" target="_blank">
											<img class="img-fluid project-image rounded shadow-sm" src="https://github.com/yl3800/EIGV/raw/main/figures/framework.png" alt="EIGV" height="150" width="160"/>
										</a>
										<div class="desc col-md-8 col-12">
											<h6><a href="https://arxiv.org/pdf/2207.12783.pdf" target="_blank">Equivariant and Invariant Grounding for Video Question Answering</a></h6>
											<p class="item-meta col-12 col-md-12 col-lg-14 "> Yicong Li, Xiang Wang, <b>Junbin Xiao</b>, Tat Seng Chua</p>
											<div class="item-meta col-12 col-md-12 col-lg-14">
												[<a href="https://dl.acm.org/doi/abs/10.1145/3503161.3548035">ACM MM'22</a>
												/ Project Page
												/ <a href="https://github.com/yl3800/EIGV" target="_blank">Github</a>
												/ Poster
												/ <a href="https://scholar.google.com/scholar_lookup?arxiv_id=2207.12783" target="_blank">Cite</a>]
											</div>                        
										</div><!--//desc-->                          
									</div><!--//item-->
									</div><!--//resume-main-->
									<div class="item mb-3">
									<div class="item row">
										<a class="col-md-3 col-5" href="https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Invariant_Grounding_for_Video_Question_Answering_CVPR_2022_paper.pdf" target="_blank">
											<img class="img-fluid project-image rounded shadow-sm" src="https://github.com/yl3800/IGV/raw/main/figures/framework.png" alt="IGV" height="160" width="160"/>
										</a>
										<div class="desc col-md-8 col-12">
											<h6><a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Invariant_Grounding_for_Video_Question_Answering_CVPR_2022_paper.pdf" target="_blank">Invariant Grounding for Video Question Answering</a></h6>
											<p class="item-meta col-12 col-md-12 col-lg-14 "> Yicong Li, Xiang Wang, <b>Junbin Xiao</b>, Wei Ji, Tat-Seng Chua</p>
											<div class="item-meta col-12 col-md-12 col-lg-14">
												[<a href="">CVPR'22</a>, <font color="#FF4500">Best Paper Finalist</font>
												/ Project Page
												/ <a href="https://github.com/yl3800/IGV" target="_blank">Github</a>												
												/ Poster
												/ <a href="https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=Annotating+Object+and+Relations+in+User-Generated+Videos&btnG=" target="_blank">Cite</a>]
											</div>                        
										</div><!--//desc-->                          
									</div><!--//item-->
									</div><!--//resume-main-->
									<div class="item mb-3">
									<div class="item row">
										<a class="col-md-3 col-5" href="https://arxiv.org/pdf/2112.06197.pdf" target="_blank">
											<img class="img-fluid project-image rounded shadow-sm" src="assets/images/research/aaai/introduction.png" alt="HQGA" height="160" width="160"/>
										</a>
										<div class="desc col-md-9 col-12">
											<h6><a href="https://arxiv.org/pdf/2112.06197.pdf" target="_blank">Video as Conditional Graph Hierarchy for Multi-Granular Question Answering</a></h6>
											<p class="item-meta col-12 col-md-12 col-lg-14 "> <b>Junbin Xiao</b>, Angela Yao, Zhiyuan Liu, Yicong Li, Wei Ji, Tat-Seng Chua</p>
											<div class="item-meta col-12 col-md-12 col-lg-14">
												[<a href="https://ojs.aaai.org/index.php/AAAI/article/view/20184">AAAI'22</a>, <font color="#FF4500">Oral</font>
												/ Project Page
												/ <a href="https://github.com/doc-doc/HQGA" target="_blank">Github</a>
												/ <a href="https://doc-doc.github.io/docs/AAAI-36-HQGA-poster.pdf">Poster </a>
												/ <a href="https://scholar.google.com.sg/scholar?q=Video+as+Conditional+Graph+Hierarchy+for+Multi-Granular+Question+Answering&hl=zh-CN&as_sdt=0&as_vis=1&oi=scholart" target="_blank">Cite</a>]
											</div>                        
										</div><!--//desc-->                          
									</div><!--//item-->
									</div><!--//resume-main-->
									<div class="item mb-3">
									<div class="item row">
										<a class="col-md-3 col-5" href="" target="_blank">
											<img class="img-fluid project-image rounded shadow-sm" src="assets/images/research/mm/VidVRD-II.png" alt="VidVRD-II" height="140" width="160"/>
										</a>
										<div class="desc col-md-8 col-12">
											<h6><a href="" target="_blank">Video Visual Relation Detection via Interactive Inference</a></h6>
											<p class="item-meta col-12 col-md-12 col-lg-14 "> Xindi Shang, Yicong Li, <b>Junbin Xiao</b>, Wei Ji, Tat-Seng Chua</p>
											<div class="item-meta col-12 col-md-12 col-lg-14">
												[<a href="https://dl.acm.org/doi/abs/10.1145/3474085.3475263">ACM MM'21</a>
												/ Project Page
												/ Github
												/ Poster
												/ <a href="https://scholar.google.com.sg/scholar?hl=zh-CN&as_sdt=0%2C5&as_vis=1&q=Video+Visual+Relation+Detection+via+Interactive+Inference&btnG=" target="_blank">Cite</a>]
											</div>                        
										</div><!--//desc-->                          
									</div><!--//item-->
									</div><!--//resume-main-->
									<div class="item mb-3">
									<div class="item row">
										<a class="col-md-3 col-5" href="https://arxiv.org/pdf/2105.08276.pdf" target="_blank">
											<img class="img-fluid project-image rounded shadow-sm" src="assets/images/research/cvpr/nextqa.png" alt="NExT-QA Dataset" height="160" width="160"/>
										</a>
										<div class="desc col-md-9 col-12">
											<h6><a href="https://arxiv.org/pdf/2105.08276.pdf" target="_blank">NExT-QA: Next Phase of Question Answering to Explaining Temporal Actions</a></h6>
											<p class="item-meta col-12 col-md-12 col-lg-14 "> <b>Junbin Xiao</b>, Xindi Shang, Yao Angela, Tat-Seng Chua</p>
											<div class="item-meta col-12 col-md-12 col-lg-14">
												[<a href="https://ieeexplore.ieee.org/document/9577425">CVPR'21</a>, <font color="#FF4500">Strong Accept</font>
												/ <a href="https://doc-doc.github.io/docs/nextqa.html" target="_blank">Project Page</a>
												/ <a href="https://github.com/doc-doc/NExT-QA" target="_blank">Github</a>
												/ <a href="https://doc-doc.github.io/docs/nextqa-cvpr21_poster.pdf">Poster</a>
												/ <a href="https://scholar.google.com/scholar_lookup?arxiv_id=2105.08276" target="_blank">Cite</a>]
											</div>                        
										</div><!--//desc-->                          
									</div><!--//item-->
									</div><!--//resume-main-->
									<div class="item mb-3">
									<div class="item row">
										<a class="col-md-3 col-5" href="" target="_blank">
											<img class="img-fluid project-image rounded shadow-sm" src="https://camo.githubusercontent.com/bd1db699a41728741495c245cbb24f2903934b8a1533a20e786879b881a12030/68747470733a2f2f6d656469612e67697068792e636f6d2f6d656469612f6c53737a745957616d7036674c66485366672f67697068792e676966" alt="Video Relation Dataset" height="160" width="160"/>
										</a>
										<div class="desc col-md-8 col-12">
											<h6><a href="" target="_blank">Visual Relation Grounding in Videos</a></h6>
											<p class="item-meta col-12 col-md-12 col-lg-14 "> <b>Junbin Xiao</b>, Xindi Shang, Xun Yang, Sheng Tang, Tat-Seng Chua</p>
											<div class="item-meta col-12 col-md-12 col-lg-14 ">
												[<a href="https://link.springer.com/chapter/10.1007/978-3-030-58539-6_27">ECCV'20</a>, <font color="#FF4500">Spotlight</font>
												/ Project Page
												/ <a href="https://github.com/doc-doc/vRGV" target="_blank">Github</a>
												/ Poster
												/ <a href="https://scholar.google.com.sg/scholar?q=visual+relation+grounding+in+videos&hl=zh-CN&as_sdt=0&as_vis=1&oi=scholart" target="_blank">Cite</a>]
											</div>                        
										</div><!--//desc-->                          
									</div><!--//item-->
									</div><!--//resume-main-->
									<div class="item mb-3">
									<div class="item row">
										<a class="col-md-3 col-5" href="" target="_blank">
											<img class="img-fluid project-image rounded shadow-sm" src="https://xdshang.github.io/docs/vidor/samples/3578746529.gif" alt="Video Relation Dataset" height="160" width="160"/>
										</a>
										<div class="desc col-md-8 col-12">
											<h6><a href="https://dl.acm.org/doi/10.1145/3323873.3325056" target="_blank">Annotating Object and Relations in User-Generated Videos</a></h6>
											<p class="item-meta col-12 col-md-12 col-lg-14 "> Xindi Shang, Donglin Di, <b>Junbin Xiao</b>, Yu Cao, Xun Yang, Tat-Seng Chua</p>										
											<p class="item-meta col-12 col-md-12 col-lg-14 ">
												[<a href="https://dl.acm.org/doi/10.1145/3323873.3325056">ICMR'19</a>, <font color="#FF4500">Oral</font>
												/ <a href="https://xdshang.github.io/docs/vidor.html" target="_blank">Project Page</a>
												/ Github
												/ Poster
												/ <a href="https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=Annotating+Object+and+Relations+in+User-Generated+Videos&btnG=" target="_blank">Cite</a>]
											</p>
										   											
										</div><!--//desc-->                          
									</div><!--//item-->
									</div><!--//resume-main-->
							</section><!--//project-section-->				
						
							<section class="project-section py-3">	
							<h3 class="text-uppercase resume-section-heading mb-4">Others</h3>
									<div class="item mb-3">
									<div class="item-content">
									<p>Reviewer for Conference: ICCV'23, CVPR'23, AAAI'23, ICASSP'23, ECCV'22, ACM MM'19&20&23 </p>
									<p>Reviewer for Journal: TMM, TNNLS, ToMM, NeurComputing, JVCIR. </p>
									</div>
								</div>
							</section>
						</div>
						<aside class="resume-aside col-12 col-lg-4 col-xl-3 px-lg-4 pb-lg-4">
							<section class="education-section py-3">
										<h3 class="text-uppercase resume-section-heading mb-4">Internship</h3>
										<ul class="list-unstyled resume-education-list">
											<li class="mb-3">
												<div class="resume-degree font-weight-bold">[Nov. 2021-Apr. 2022]</div>
												<div class="resume-degree font-weight-bold">Research Intern</div>
												<div class="resume-degree-org text-muted"><a href="https://sail.sea.com/" target="_blank"><b>Sea AI Lab (SAIL)</b></a></div>
											</li>
											<li class="mb-3">
												<div class="resume-degree font-weight-bold">[Jun. 2017- Sep. 2019]</div>
												<div class="resume-degree font-weight-bold">Algorithm Engineer</div>
												<div class="resume-degree-org text-muted"><a href="https://weixin.qq.com/" target="_blank"><b>Weixin, Tencent</b></a></div>
											</li>
										</ul>
									</section><!--//education-section-->
									<section class="education-section py-3">
										<h3 class="text-uppercase resume-section-heading mb-4">Competition</h3>
										<ul class="list-unstyled resume-education-list">
											<li class="mb-3">
												<div class="resume-degree font-weight-bold">ILSVRC2017 (VID)</div>
												<div class="resume-degree-org text-muted"><a href="https://image-net.org/challenges/LSVRC/2017/results.php" target="_blank">THU-CAS: Ranked 3rd</a></div>
											</li>
											<li class="mb-3">
												<div class="resume-degree font-weight-bold">ILSVRC2016 (VID)</div>
												<div class="resume-degree-org text-muted"><a href="https://image-net.org/challenges/LSVRC/2016/results.php" target="_blank">MCG-ICT-CAS: Ranked 3rd</a></div>
											</li>
											<li class="mb-3">
												<div class="resume-degree font-weight-bold">ILSVRC2015 (CLS-LOC)</div>
												<div class="resume-degree-org text-muted"><a href="https://image-net.org/challenges/LSVRC/2015/results.php" target="_blank">MCG-ICT-CAS: Ranked 5th</a></div>
											</li>
										</ul>
									</section><!--//education-section-->
									<section class="education-section py-3">
										<h3 class="text-uppercase resume-section-heading mb-4">TA</h3>
										<ul class="list-unstyled resume-education-list">
											<li class="mb-3">
												<div class="resume-degree font-weight-bold">[Sem 2020-2021]</div>
												<div class="resume-degree-org text-muted"><a href="https://nusmods.com/modules/CS5228/knowledge-discovery-and-data-mining" target="_blank">CS5228: Knowledge Discovery and Data Mining</a></div>
											</li>
											<li class="mb-3">
												<div class="resume-degree font-weight-bold">[Sem 2019-2020]</div>
												<div class="resume-degree-org text-muted"><a href="https://nusmods.com/modules/CS4243/computer-vision-and-pattern-recognition" target="_blank">CS4243: Computer Vision and Pattern Recognition</a></div>
											</li>
											<!-- <li class="mb-3">
												<div class="resume-degree font-weight-bold">[Aug 2020]</div>
												<div class="resume-degree-org text-muted"><b>Presentation in VisDA Challenge 2020 as one of the winners. <a href="./projects/visda.html" target="_blank">[records]</a></b></div>
											</li> -->
										</ul>
									</section><!--//education-section-->
									<section class="skills-section py-3">
										<h3 class="text-uppercase resume-section-heading mb-4">Awards</h3>
										<ul class="list-unstyled resume-lang-list">
											<ul >
												<li> Dean's Graduate Research Excellence Award (NUS) </li>
												<li> AAAI Student Scholarship</li>
												<li> NUS Research Achievement</li>
											    <li> NUS Research Scholarship</li>
												<li> CAS 1st-class Scholarship</li>
												<li> Outstanding Graduate (SCU)</li>
												<li> National Scholarship (SCU)</li>
											</ul>
										</ul>
									</section><!--//certificates-section-->
									<section class="skills-section py-3">
										<h3 class="text-uppercase resume-section-heading mb-4">Other Links</h3>
										<ul class="list-unstyled resume-lang-list">
											<ul >											
												<li> <a href="https://aideadlin.es/?sub=ML,CV,CG,NLP,RO,SP,DM,KR" target="_blank">CS Conference Deadline</a></li>
												<li> <a href="https://www.ccf.org.cn/Academic_Evaluation/By_category/" target="_blank">Recommended Conference and Journal List (CCF)</a></li>
												<li> <a href="https://numbda.cs.tsinghua.edu.cn/~yuwj/TH-CPL.pdf" target="_blank">Recommended Conference and Journal List (THU)</a></li>										
											</ul>
										</ul>
									</section><!--//certificates-section-->
									
									<a href='https://clustrmaps.com/site/1bo5y'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=3cc659&w=300&t=tt&d=1NMB03mBvqOWNVMLTaTXZqefc4r-e3mZT-vRyxZ_l8s&co=ffffff&ct=808080' width="250"/></a>
							        
								</aside><!--//resume-aside-->
							</div><!--//row-->
						</div><!--//resume-body-->
						<hr>
						
					</article>
					
				</div><!--//container-->
				
				<footer class="footer text-center py-4">
					<!--/* This template is free as long as you keep the footer attribution link. If you'd like to use the template without the attribution link, you can buy the commercial license via: themes.3rdwavemedia.com Thank you for your support. :) */-->
					<small class="copyright text-muted">Designed based on <a class="theme-link" href="https://themes.3rdwavemedia.com/demo/bs5/devresume/" target="_blank">Xiaoying Riley</a> and <a class="theme-link" href="https://jonbarron.info/" target="_blank">Jon Barron</a> </small>
				</footer>
				
			</div><!--//main-wrapper-->
			

</body>
</html> 

